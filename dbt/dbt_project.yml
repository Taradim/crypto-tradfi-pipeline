name: "data_pipeline_portfolio"
version: "1.0.0"
config-version: 2

# This setting configures which "profile" dbt uses for this project.
profile: "data_pipeline_portfolio"

# These configurations specify where dbt should look for different types of files.
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

target-path: "target"
clean-targets:
  - "target"
  - "dbt_packages"

# Optional: Configure on-run-start hook for additional S3 setup
# Note: S3 credentials are configured via profiles.yml settings
# Uncomment if you need additional S3 configuration:
# on-run-start:
#   - "{{ configure_s3() }}"

# Variables (no default - dbt will fail if S3_BUCKET_NAME is not set)
vars:
  s3_bucket_name: "{{ env_var('S3_BUCKET_NAME') }}"

# Configuring models
# Full documentation: https://docs.getdbt.com/reference/model-configs
# Aligned with Bronze/Silver/Gold architecture
# Note: Bronze data is written by Python pipelines, dbt starts at Silver layer
models:
  data_pipeline_portfolio:
    silver:
      +materialized: view
      +schema: silver
      description: "Silver layer models - read from S3 bronze, clean and standardize data"
    gold:
      +materialized: table
      +schema: gold
      description: "Gold layer models - business-ready analytical data for BI and dashboards"
